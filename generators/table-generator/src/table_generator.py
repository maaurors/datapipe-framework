#!/usr/bin/env python3
"""Generic Table Generator for DataPipe Framework"""

import json
from typing import Dict, List, Any
import argparse

class GenericTableGenerator:
    def __init__(self, table_name: str = "", cloud: str = "gcp", load_mode: str = "incremental"):
        self.table_name = table_name
        self.cloud = cloud
        self.load_mode = load_mode
        
    def generate_ddl(self, schema_config: Dict[str, Any]) -> str:
        """Generate DDL based on cloud provider"""
        if self.cloud == "gcp":
            return self._generate_bigquery_ddl(schema_config)
        elif self.cloud == "aws":
            return self._generate_redshift_ddl(schema_config)
        elif self.cloud == "azure":
            return self._generate_synapse_ddl(schema_config)
        else:
            return self._generate_bigquery_ddl(schema_config)
    
    def _generate_bigquery_ddl(self, schema_config: Dict[str, Any]) -> str:
        """Generate BigQuery DDL"""
        table_name = schema_config.get("table_name", self.table_name)
        columns = schema_config.get("columns", [])
        
        ddl = f"CREATE OR REPLACE TABLE project.dataset.dep_{table_name} (\n"
        
        for col in columns:
            col_name = col.get("name", "").lower()
            col_type = self._map_to_bigquery_type(col.get("type", "STRING"))
            description = col.get("description", "")
            
            ddl += f"  {col_name} {col_type}"
            if description:
                ddl += f" OPTIONS(description='{description}')"
            ddl += ",\n"
        
        ddl = ddl.rstrip(",\n") + "\n)\n"
        ddl += "PARTITION BY DATE(fecha_creacion)\n"
        ddl += "CLUSTER BY id, estado\n"
        ddl += "OPTIONS(description='Table generated by DataPipe Framework');"
        
        return ddl
    
    def _generate_redshift_ddl(self, schema_config: Dict[str, Any]) -> str:
        """Generate Redshift DDL"""
        table_name = schema_config.get("table_name", self.table_name)
        columns = schema_config.get("columns", [])
        
        ddl = f"CREATE TABLE IF NOT EXISTS schema.dep_{table_name} (\n"
        
        for col in columns:
            col_name = col.get("name", "").lower()
            col_type = self._map_to_redshift_type(col.get("type", "VARCHAR"))
            ddl += f"  {col_name} {col_type},\n"
        
        ddl = ddl.rstrip(",\n") + "\n);"
        return ddl
    
    def _generate_synapse_ddl(self, schema_config: Dict[str, Any]) -> str:
        """Generate Azure Synapse DDL"""
        table_name = schema_config.get("table_name", self.table_name)
        columns = schema_config.get("columns", [])
        
        ddl = f"CREATE TABLE [schema].[dep_{table_name}] (\n"
        
        for col in columns:
            col_name = col.get("name", "").lower()
            col_type = self._map_to_synapse_type(col.get("type", "VARCHAR"))
            ddl += f"  [{col_name}] {col_type},\n"
        
        ddl = ddl.rstrip(",\n") + "\n);"
        return ddl
    
    def _map_to_bigquery_type(self, source_type: str) -> str:
        type_map = {
            "STRING": "STRING",
            "NUMERIC": "NUMERIC", 
            "INT64": "INT64",
            "FLOAT64": "FLOAT64",
            "DATE": "DATE",
            "TIMESTAMP": "TIMESTAMP"
        }
        return type_map.get(source_type.upper(), "STRING")
    
    def _map_to_redshift_type(self, source_type: str) -> str:
        type_map = {
            "STRING": "VARCHAR(255)",
            "NUMERIC": "DECIMAL(18,2)",
            "INT64": "BIGINT", 
            "FLOAT64": "FLOAT8",
            "DATE": "DATE"
        }
        return type_map.get(source_type.upper(), "VARCHAR(255)")
    
    def _map_to_synapse_type(self, source_type: str) -> str:
        type_map = {
            "STRING": "VARCHAR(255)",
            "NUMERIC": "DECIMAL(18,2)",
            "INT64": "BIGINT",
            "FLOAT64": "FLOAT",
            "DATE": "DATE"
        }
        return type_map.get(source_type.upper(), "VARCHAR(255)")

def main():
    parser = argparse.ArgumentParser(description='Generic Table Generator')
    parser.add_argument('--table-name', type=str, help='Table name')
    parser.add_argument('--cloud', type=str, default='gcp', help='Cloud provider')
    parser.add_argument('--load-mode', type=str, default='incremental', help='Load mode')
    
    args = parser.parse_args()
    
    generator = GenericTableGenerator(
        table_name=args.table_name or "generic_table",
        cloud=args.cloud,
        load_mode=args.load_mode
    )
    
    sample_config = {
        "table_name": args.table_name or "generic_table",
        "columns": [
            {"name": "ID", "type": "NUMERIC", "description": "Primary key"},
            {"name": "NOMBRE", "type": "STRING", "description": "Name field"},
            {"name": "FECHA_CREACION", "type": "DATE", "description": "Creation date"}
        ]
    }
    
    ddl = generator.generate_ddl(sample_config)
    print("=== TABLE DDL ===")
    print(ddl)

if __name__ == "__main__":
    main()
